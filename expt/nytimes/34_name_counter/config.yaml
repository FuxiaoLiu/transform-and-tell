dataset_reader:
  type: nytimes_position
  tokenizer:
    type: word
    word_splitter: just_spaces_keep_newlines
  token_indexers:
    roberta:
      type: roberta
      model_name: roberta-base
      namespace: bpe
      padding_on_right: true
      padding_value: 1
      max_len: 512
  image_dir: data/nytimes/images_processed
  lazy: true
train_data_path: train
validation_data_path: valid
test_data_path: test
vocabulary:
  type: roberta
  directory_path: ./expt/vocabulary
model:
  type: word_counter
  padding_value: 1
iterator:
  type: basic
  batch_size: 128
  max_instances_in_memory: 8192
trainer:
  type: callback_apex
  apex_opt_level: O2
  keep_batchnorm_fp32: true
  optimizer:
    type: bert_adam
    lr: 0.0001
    warmup: 0.05
    t_total: 437600 # Takees 43m to go through 4376 batches per epoch
    schedule: warmup_linear
    b1: 0.9
    b2: 0.98
    e: 0.000001
    weight_decay: 0.00001 # Worse choices: 0.01, 0.001, 0.000001
    max_grad_norm: 0.1 # Worse choices: 1.0
  no_grad:
    - ^resnet
    - ^roberta
  num_epochs: 1
  shuffle: false
  cuda_device: 0
  callbacks:
    - type: track_metrics
      patience: 30
    - type: log_to_tensorboard
      summary_interval: 512
      should_log_parameter_statistics: false
      log_batch_size_period: 1024
